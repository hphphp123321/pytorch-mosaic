import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import transforms
from torchvision.utils import save_image
from vae import VAE
import ssl
ssl._create_default_https_context = ssl._create_unverified_context


def train(save_file, dataset):
    # Device configuration
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Create a directory if not exists
    sample_dir = 'samples'
    if not os.path.exists(sample_dir):
        os.makedirs(sample_dir)

    # Hyper-parameters
    image_size = 32 * 32 * 3
    z_dim = 512
    num_epochs = 100
    batch_size = 128
    learning_rate = 1e-3




    # Data loader
    data_loader = torch.utils.data.DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=True,
    )

    model = VAE().to(device)
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.85)

    # Start training
    for epoch in range(num_epochs):
        scheduler.step()
        for i, (x, _) in enumerate(data_loader):
            # Forward pass
            x = x.to(device)#.view(-1, image_size)
            x_reconst, mu, log_var = model(x)

            # Compute reconstruction loss and kl divergence
            # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43
            reconst_loss = F.mse_loss(x_reconst, x, size_average=False)
            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())

            # Backprop and optimize
            loss = reconst_loss #+ kl_div
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i+1) % 10 == 0:
                print("Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}"
                       .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))

        with torch.no_grad():
            # Save the sampled images
            z = torch.randn(batch_size, z_dim).to(device)
            out = model.decode(z).view(-1, 3, 32, 32)
            save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))

            # Save the reconstructed images
            out, _, _ = model(x)
            x_concat = torch.cat([x.view(-1, 3, 32, 32), out.view(-1, 3, 32, 32)], dim=3)
            save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))

        # Save models
        torch.save(model, save_file)


if __name__ == '__main__':

    transform = transforms.Compose([
        transforms.Resize([8, 8]),
        transforms.ToTensor()
    ])

    dataset = torchvision.datasets.CIFAR10(
        './data/cifar10/',
        train=True,
        transform=transform,
        target_transform=None,
        download=True
    )

    model_file = 'models/conv_vae.pt'
    os.makedirs('models/', exist_ok=True)
    train(model_file, dataset)
